{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOoJmCYxGenmOEDXf8/0hml"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Download necessary NLTK resources\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Load datasets\n","fake_df = pd.read_csv(\"Fake.csv\")\n","real_df = pd.read_csv(\"True.csv\")\n","\n","# Add labels: 0 = Fake, 1 = Real\n","fake_df[\"label\"] = 0\n","real_df[\"label\"] = 1\n","\n","# Combine datasets\n","df = pd.concat([fake_df, real_df]).reset_index(drop=True)\n","\n","# Shuffle data\n","df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","# Drop unnecessary columns if they exist\n","df = df[['text', 'label']]\n","\n","# Define text preprocessing function\n","stop_words = set(stopwords.words('english'))\n","lemmatizer = WordNetLemmatizer()\n","\n","def preprocess_text(text):\n","    text = text.lower()  # Lowercase\n","    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n","    text = re.sub(r'\\d+', '', text)  # Remove numbers\n","    words = text.split()\n","    words = [word for word in words if word not in stop_words]  # Remove stopwords\n","    words = [lemmatizer.lemmatize(word) for word in words]  # Lemmatization\n","    return \" \".join(words)\n","\n","# Apply preprocessing\n","df[\"clean_text\"] = df[\"text\"].apply(preprocess_text)\n","\n","# Convert text to numerical features (TF-IDF)\n","vectorizer = TfidfVectorizer(max_features=5000)\n","X = vectorizer.fit_transform(df[\"clean_text\"])\n","y = df[\"label\"]\n","\n","# Split into train/test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(f\"Training samples: {X_train.shape[0]}, Testing samples: {X_test.shape[0]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rwi_jAj2m9s6","executionInfo":{"status":"ok","timestamp":1742475208446,"user_tz":-300,"elapsed":77966,"user":{"displayName":"Muneeb Iqbal","userId":"08594350093679172608"}},"outputId":"6e586ab7-fe4d-4b29-87b6-c3a3f8b26b05"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Training samples: 35918, Testing samples: 8980\n"]}]},{"cell_type":"code","source":["from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, classification_report\n","import joblib\n","\n","# Train Naïve Bayes\n","nb_model = MultinomialNB()\n","nb_model.fit(X_train, y_train)\n","\n","# Evaluate\n","y_pred_nb = nb_model.predict(X_test)\n","print(\"Naïve Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n","print(classification_report(y_test, y_pred_nb))\n","\n","# Save model\n","joblib.dump(nb_model, \"naive_bayes_model.pkl\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HnseCBbKnBna","executionInfo":{"status":"ok","timestamp":1742475227791,"user_tz":-300,"elapsed":333,"user":{"displayName":"Muneeb Iqbal","userId":"08594350093679172608"}},"outputId":"7a023696-99bc-4017-dab5-dd8dc759b6ae"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Naïve Bayes Accuracy: 0.9300668151447662\n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.93      0.93      4710\n","           1       0.93      0.93      0.93      4270\n","\n","    accuracy                           0.93      8980\n","   macro avg       0.93      0.93      0.93      8980\n","weighted avg       0.93      0.93      0.93      8980\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["['naive_bayes_model.pkl']"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","# Train Random Forest\n","rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf_model.fit(X_train, y_train)\n","\n","# Evaluate\n","y_pred_rf = rf_model.predict(X_test)\n","print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n","print(classification_report(y_test, y_pred_rf))\n","\n","# Save model\n","joblib.dump(rf_model, \"random_forest_model.pkl\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gav0n6yKne_w","executionInfo":{"status":"ok","timestamp":1742475316812,"user_tz":-300,"elapsed":79163,"user":{"displayName":"Muneeb Iqbal","userId":"08594350093679172608"}},"outputId":"c5bb65fd-b3d5-45d5-8579-ce1d65795b56"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Forest Accuracy: 0.9974387527839643\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      4710\n","           1       1.00      1.00      1.00      4270\n","\n","    accuracy                           1.00      8980\n","   macro avg       1.00      1.00      1.00      8980\n","weighted avg       1.00      1.00      1.00      8980\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["['random_forest_model.pkl']"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["import joblib\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","\n","# Split into training & testing sets\n","train_texts, test_texts, train_labels, test_labels = train_test_split(\n","    df['text'], df['label'], test_size=0.2, random_state=42\n",")\n","\n","# Create and fit TF-IDF vectorizer\n","vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n","vectorizer.fit(train_texts)\n","\n","# Save TF-IDF vectorizer\n","joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n","print(\"TF-IDF Vectorizer has been created and saved successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"emnBSlvHppX2","executionInfo":{"status":"ok","timestamp":1742492590861,"user_tz":-300,"elapsed":14868,"user":{"displayName":"Muneeb Iqbal","userId":"08594350093679172608"}},"outputId":"e7c71427-3e43-46a1-cc4c-e4c13bd039e2"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["TF-IDF Vectorizer has been created and saved successfully!\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","\n","# Tokenization\n","tokenizer = Tokenizer(num_words=5000)\n","tokenizer.fit_on_texts(df['clean_text'])\n","\n","# Convert text to sequences\n","X_sequences = tokenizer.texts_to_sequences(df['clean_text'])\n","X_padded = pad_sequences(X_sequences, maxlen=500, padding='post')\n","\n","# Split data\n","X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n","\n","# Define LSTM model\n","embedding_dim = 128\n","\n","lstm_model = Sequential([\n","    Embedding(input_dim=5000, output_dim=embedding_dim, input_length=500),\n","    LSTM(100, return_sequences=True),\n","    Dropout(0.2),\n","    LSTM(100),\n","    Dropout(0.2),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","# Compile model\n","lstm_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n","\n","# Train model\n","lstm_model.fit(X_train_lstm, y_train_lstm, epochs=5, batch_size=32, validation_data=(X_test_lstm, y_test_lstm))\n","\n","# Save model\n","lstm_model.save(\"lstm_model.h5\")\n","joblib.dump(tokenizer, \"tokenizer.pkl\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxK3enznnheQ","executionInfo":{"status":"ok","timestamp":1742481961489,"user_tz":-300,"elapsed":1023084,"user":{"displayName":"Muneeb Iqbal","userId":"08594350093679172608"}},"outputId":"3164c84a-445a-4ff7-c671-b59b9b633a14"},"execution_count":8,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1278s\u001b[0m 1s/step - accuracy: 0.5194 - loss: 0.6892 - val_accuracy: 0.5415 - val_loss: 0.8501\n","Epoch 2/5\n","\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1255s\u001b[0m 1s/step - accuracy: 0.5478 - loss: 0.6623 - val_accuracy: 0.9616 - val_loss: 0.1282\n","Epoch 3/5\n","\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1354s\u001b[0m 1s/step - accuracy: 0.9638 - loss: 0.1228 - val_accuracy: 0.9893 - val_loss: 0.0297\n","Epoch 4/5\n","\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1354s\u001b[0m 1s/step - accuracy: 0.9910 - loss: 0.0316 - val_accuracy: 0.9930 - val_loss: 0.0334\n","Epoch 5/5\n","\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1354s\u001b[0m 1s/step - accuracy: 0.9947 - loss: 0.0199 - val_accuracy: 0.9951 - val_loss: 0.0169\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"execute_result","data":{"text/plain":["['tokenizer.pkl']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["!pip install streamlit\n","!pip install pyngrok"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vK23mDQ9BzdC","executionInfo":{"status":"ok","timestamp":1742484012183,"user_tz":-300,"elapsed":14683,"user":{"displayName":"Muneeb Iqbal","userId":"08594350093679172608"}},"outputId":"4ab1b367-f458-47ab-8893-1b63957357c7"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting streamlit\n","  Downloading streamlit-1.43.2-py2.py3-none-any.whl.metadata (8.9 kB)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n","Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n","Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n","Collecting watchdog<7,>=2.1.5 (from streamlit)\n","  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.30.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n","Downloading streamlit-1.43.2-py2.py3-none-any.whl (9.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n","Successfully installed pydeck-0.9.1 streamlit-1.43.2 watchdog-6.0.0\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"]}]},{"cell_type":"code","source":["!ngrok authtoken 2uaQbgREFUSAmbgpx1VPWVMdMFe_2SYiPu9V2ELnCxHDhAavP\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IjLSDKvkK5OI","executionInfo":{"status":"ok","timestamp":1742484612578,"user_tz":-300,"elapsed":589,"user":{"displayName":"Muneeb Iqbal","userId":"08594350093679172608"}},"outputId":"210e051c-cfbb-46cd-a582-1de74f9c9c1e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"2JAX0LyuLXXa"},"execution_count":null,"outputs":[]}]}